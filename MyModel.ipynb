{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "from pycparser import c_generator\n",
    "import ForPragmaExtractor.visitors as visitor\n",
    "from Model import tokenizer\n",
    "\n",
    "VAR_PREFIX = \"var\"\n",
    "ARR_PREFIX = \"arr\"\n",
    "FUNC_PREFIX = \"func\"\n",
    "STRUCT_PREFIX = \"struct\"\n",
    "generator = c_generator.CGenerator()\n",
    "id_v = visitor.CounterIdVisitor()\n",
    "replacer = visitor.ReplaceIdsVisitor(VAR_PREFIX, ARR_PREFIX, STRUCT_PREFIX, FUNC_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1:\n",
      " {'text': [\" For: Assignment: = ID: i Constant: int, 0 BinaryOp: < ID: i ID: ni UnaryOp: p++ ID: i For: Assignment: = ID: j Constant: int, 0 BinaryOp: < ID: j ID: nl UnaryOp: p++ ID: j Assignment: = ArrayRef: ArrayRef: ID: D ID: i ID: j BinaryOp: / BinaryOp: * Cast: Typename: None, [] TypeDecl: None, [] IdentifierType: ['double'] ID: i BinaryOp: + ID: j Constant: int, 2 ID: nk\"]}\n",
      "after tokenized:\n",
      " {'input_ids': [[0, 286, 35, 46091, 35, 5457, 4576, 35, 939, 33685, 35, 6979, 6, 321, 47466, 13926, 35, 28696, 4576, 35, 939, 4576, 35, 10265, 1890, 1766, 13926, 35, 181, 42964, 4576, 35, 939, 286, 35, 46091, 35, 5457, 4576, 35, 1236, 33685, 35, 6979, 6, 321, 47466, 13926, 35, 28696, 4576, 35, 1236, 4576, 35, 295, 462, 1890, 1766, 13926, 35, 181, 42964, 4576, 35, 1236, 46091, 35, 5457, 42719, 31842, 35, 42719, 31842, 35, 4576, 35, 211, 4576, 35, 939, 4576, 35, 1236, 47466, 13926, 35, 1589, 47466, 13926, 35, 1009, 6719, 35, 5957, 9675, 4344, 35, 9291, 6, 48081, 7773, 45788, 35, 9291, 6, 48081, 28763, 24072, 40118, 35, 47052, 14582, 44403, 4576, 35, 939, 47466, 13926, 35, 2055, 4576, 35, 1236, 33685, 35, 6979, 6, 132, 4576, 35, 295, 330, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "token_len: 134 134\n",
      "vocab_size:  50265\n"
     ]
    }
   ],
   "source": [
    "def db_read_string_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return \"\".join(f.readlines())   # readlines()是读全部\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def normalize_code_as_ast(pickle_file):\n",
    "    # print (pickle_file)\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        pragmafor_tuple = pkl.load(f)  #\n",
    "        for_ast = pragmafor_tuple.for_node\n",
    "        # for_ast.show()\n",
    "        # print(normalize_code_as_string.generator.visit(for_ast))\n",
    "        # for_ast.show()\n",
    "        # counts in an array the name and identifiers of the code\n",
    "        id_v.reset()\n",
    "        id_v.visit(for_ast)\n",
    "        # Replace the names..\n",
    "        replacer.reset(id_v.ids, id_v.array,id_v.struct, id_v.func)\n",
    "        replacer.visit(for_ast)\n",
    "        with open('temp.txt', 'w') as f:\n",
    "            for_ast.show(buf=f)\n",
    "        with open('temp.txt', 'r') as f:\n",
    "            ast = f.readlines()\n",
    "\n",
    "        ast_no_whitespaces = [a.strip() for a in ast] # kill all whitespaces\n",
    "        # print(ast_no_whitespaces)\n",
    "        # print(normalize_code_as_string.generator.visit(for_ast))\n",
    "\n",
    "        # print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "        ast_one_line = \" \" + \" \".join(ast_no_whitespaces)\n",
    "        return ast_one_line\n",
    "\n",
    "\n",
    "# str1 = normalize_code_as_ast('DB_TEST/DB_TEST/database/PolyBench-ACC-master_.gitignore_2mm.c_5/code_pickle.pkl')\n",
    "# print(str1)\n",
    "\n",
    "def code_as_ast(pickle_file):\n",
    "    # print (pickle_file)\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        pragmafor_tuple = pkl.load(f)  #\n",
    "        for_ast = pragmafor_tuple.for_node\n",
    "        with open('temp.txt', 'w') as f:\n",
    "            for_ast.show(buf=f)\n",
    "        with open('temp.txt', 'r') as f:\n",
    "            ast = f.readlines()\n",
    "\n",
    "        ast_no_whitespaces = [a.strip() for a in ast] # kill all whitespaces and \\n\n",
    "        ast_one_line = \" \" + \" \".join(ast_no_whitespaces)\n",
    "        return ast_one_line\n",
    "\n",
    "\n",
    "str2 = code_as_ast('/Users/solochan/PycharmProjects/PragFormer/DB_TEST/database/PolyBench-ACC-master_.gitignore_2mm.c_5/code_pickle.pkl')\n",
    "# print(str2)\n",
    "# print('str2len: ', len(str2))\n",
    "\n",
    "data1 = {'text': [str2]}\n",
    "print(\"data1:\\n\", data1)\n",
    "\n",
    "text, _ = tokenizer.deepscc_tokenizer(data1['text'])\n",
    "print(\"after tokenized:\\n\", text)\n",
    "print('token_len:', len(text.input_ids[0]), len(text.attention_mask[0]))\n",
    "\n",
    "print(\"vocab_size: \", _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_set['text'][0]\n",
      " for (j = 0; j < prm->Natom; j++)\n",
      "{\n",
      "  for (i = 1; i < numcopies; i++)\n",
      "  {\n",
      "    sumdeijda[j] += sumdeijda[(prm->Natom * i) + j];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "data_set['text'][10]\n",
      " for (i = -1; i < prm->Natom; i++)\n",
      "{\n",
      "  iexw[eoff + i] = -1;\n",
      "}\n",
      "\n",
      "data_set['ast'][0]\n",
      "  For: Assignment: = ID: j Constant: int, 0 BinaryOp: < ID: j StructRef: -> ID: prm ID: Natom UnaryOp: p++ ID: j Compound: For: Assignment: = ID: i Constant: int, 1 BinaryOp: < ID: i ID: numcopies UnaryOp: p++ ID: i Compound: Assignment: += ArrayRef: ID: sumdeijda ID: j ArrayRef: ID: sumdeijda BinaryOp: + BinaryOp: * StructRef: -> ID: prm ID: Natom ID: i ID: j\n",
      "data_set['ast'][10]\n",
      "  For: Assignment: = ID: i UnaryOp: - Constant: int, 1 BinaryOp: < ID: i StructRef: -> ID: prm ID: Natom UnaryOp: p++ ID: i Compound: Assignment: = ArrayRef: ID: iexw BinaryOp: + ID: eoff ID: i UnaryOp: - Constant: int, 1\n",
      "data_set['label'][0]\n",
      " omp parallel for private(i, j) schedule(dynamic, blocksize)\n",
      "data_set['label'][10]\n",
      " 0\n",
      "['omp parallel for private(i, j) schedule(dynamic, blocksize)', 'omp parallel for private(i, j) schedule(dynamic, blocksize)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(progress,status) omp_throttle(1)', 'omp parallel for schedule(dynamic,4) shared(progress,status) omp_throttle(1)', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status) omp_throttle(1)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(static,1) shared(progress, status) omp_throttle(1)', 'omp parallel for schedule(static,8) shared(progress,status) omp_throttle(1)', 'omp parallel for schedule(static,1) shared(progress,status) omp_throttle(1)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for private (i)', 'omp parallel for private (i)', 'omp parallel for private (j)', 'omp parallel for private (j2, i)', '0', '0', 'omp parallel for private (i)', 'omp parallel for private (j)', 'omp parallel for private (j2, i)', '0', '0', 'omp parallel for private (j, k)', 'omp parallel for private (j, k)', '0', '0', '0', '0', '0', 'omp parallel for private(k)', 'omp parallel for private(j,k)', 'omp parallel for', '0', '0', '0', '0', '0', 'omp parallel for', 'omp parallel for private (j)', '0', '0', '0', 'omp parallel for', 'omp parallel for private (j)', '0', '0', '0', '0', 'omp parallel for private (j,k)', '0', '0', 'omp parallel for private (q, p, s)', '0', '0', '0', 'omp parallel for private (j, k)', '0', '0', '0', '0', 'omp parallel for private (j)', 'omp parallel for private (j)', 'omp parallel for', 'omp parallel for private (j)', '0', '0', 'omp parallel for private (j)', '0', '0', 'omp parallel for', 'omp parallel for', '0', '0', 'omp parallel for private(j,acc,k)', '0', '0', '0', 'omp parallel for private (j) schedule(static)', 'omp parallel for private (j, k) schedule(static)', '0', '0', '0', 'omp parallel for private(j)', 'omp parallel for private(j,k)', '0', '0', '0', 'omp parallel for schedule(static)', '0', '0', 'omp parallel for private (j, k)', '0', '0', 'omp parallel for private (i)', 'omp parallel for', '0', '0', 'omp parallel for private (j)', 'omp parallel for private (j, k)', '0', 'omp parallel for private (i, j)', '0', '0', '0', '0', '0', 'omp parallel for private (j, i)', '0', '0', 'omp parallel for private (j, w)', 'omp parallel for private (j, w)', '0', '0', '0', 'omp parallel for private (i, cnt) collapse(2) schedule(static)', 'omp parallel for private (i, cnt) collapse(2) schedule(static)', 'omp parallel for', 'omp parallel for private (i) collapse(2) schedule(static)', '0', '0', 'omp parallel for', 'omp parallel for', 'omp parallel for', 'omp parallel for', 'omp parallel for', 'omp parallel for', '0', '0', 'omp parallel for private(j) collapse(2) schedule(static)', '0', '0', 'omp parallel for private (j,k) collapse(2)', '0', '0', 'omp parallel for', 'omp parallel for private(i,j) collapse(2) schedule(static)', 'omp parallel for private(i,j) collapse(2) schedule(static)', 'omp parallel for private(i,j) collapse(2) schedule(static)', '0', '0', '0', 'omp parallel for private (iy, ix)', '0', '0', '0', '0', '0', 'omp parallel for schedule(static)', 'omp parallel for schedule(static)', '0', '0', 'omp parallel for schedule(static)', 'omp parallel for schedule(static)', '0', '0', 'omp parallel for private(i,j,t) schedule(static) collapse (2)', '0', '0', 'omp parallel for']\n",
      "['2', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2', '2', '2', '2', '0', '0', '2', '2', '2', '0', '0', '2', '2', '0', '0', '0', '0', '0', '2', '2', '1', '0', '0', '0', '0', '0', '1', '2', '0', '0', '0', '1', '2', '0', '0', '0', '0', '2', '0', '0', '2', '0', '0', '0', '2', '0', '0', '0', '0', '2', '2', '1', '2', '0', '0', '2', '0', '0', '1', '1', '0', '0', '2', '0', '0', '0', '2', '2', '0', '0', '0', '2', '2', '0', '0', '0', '1', '0', '0', '2', '0', '0', '2', '1', '0', '0', '2', '2', '0', '2', '0', '0', '0', '0', '0', '2', '0', '0', '2', '2', '0', '0', '0', '2', '2', '1', '2', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '2', '0', '0', '2', '0', '0', '1', '2', '2', '2', '0', '0', '0', '2', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '2', '0', '0', '1']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    数据处理\n",
    "\"\"\"\n",
    "data_set = {'text':[], 'label':[], 'ast':[]}\n",
    "jsonpath = '/Users/solochan/PycharmProjects/PragFormer/DB_TEST/database.json'\n",
    "with open(jsonpath, 'r') as f:\n",
    "    file_data = json.load(f)\n",
    "    for i, key in enumerate(file_data):\n",
    "        code = db_read_string_from_file(file_data[key][\"code\"])\n",
    "        ast_str = code_as_ast(file_data[key]['code_pickle'])\n",
    "        if file_data[key]['pragma']:\n",
    "            pragma = db_read_string_from_file(file_data[key]['pragma'])\n",
    "        else:\n",
    "            pragma = '0'\n",
    "\n",
    "        data_set['text'].append(code)\n",
    "        data_set['ast'].append(ast_str)\n",
    "        data_set['label'].append(pragma)\n",
    "\n",
    "print(\"data_set['text'][0]\\n\", data_set['text'][0])\n",
    "print(\"data_set['text'][10]\\n\", data_set['text'][10])\n",
    "print(\"data_set['ast'][0]\\n\", data_set['ast'][0])\n",
    "print(\"data_set['ast'][10]\\n\", data_set['ast'][10])\n",
    "print(\"data_set['label'][0]\\n\", data_set['label'][0])\n",
    "print(\"data_set['label'][10]\\n\", data_set['label'][10])\n",
    "\n",
    "def label_encoder(labels:list):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        if 'omp parallel for' in label and 'private' not in label and 'reduction' not in label:\n",
    "            new_labels.append('1')\n",
    "        elif 'omp parallel for' in label and 'private' in label and 'reduction' not in label:\n",
    "            new_labels.append('2')\n",
    "        elif 'omp parallel for' in label and 'reduction' in label and 'private' not in label:\n",
    "            new_labels.append('3')\n",
    "        elif 'omp parallel for' in label and 'reduction' in label and 'private' in label:\n",
    "            new_labels.append(\"4\")\n",
    "        else:\n",
    "            new_labels.append(\"0\")\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     return {\n",
    "#         'input_ids': pad_sequence([item['input_ids'] for item in batch], batch_first=True),\n",
    "#         'attention_mask': pad_sequence([item['attention_mask'] for item in batch], batch_first=True),\n",
    "#         'labels': torch.tensor([item['labels'] for item in batch])\n",
    "#     }\n",
    "#\n",
    "print(data_set['label'])\n",
    "data_set['label'] = label_encoder(data_set['label'])\n",
    "print(data_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/solochan/anaconda3/envs/Pragformer/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (266) must match the size of tensor b (48) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    100\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m    102\u001b[0m         inputs_text \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    103\u001b[0m         attention_mask_text \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pragformer/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/Pragformer/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pragformer/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 61\u001b[0m, in \u001b[0;36mcustom_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     58\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# 使用 pad_sequence 进行填充\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m input_ids_text \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m attention_mask_text \u001b[38;5;241m=\u001b[39m pad_sequence(attention_mask_text, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m input_ids_ast \u001b[38;5;241m=\u001b[39m pad_sequence(input_ids_ast, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pragformer/lib/python3.10/site-packages/torch/nn/utils/rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    395\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (266) must match the size of tensor b (48) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "\n",
    "# 加载预训练的BERT模型和tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "# 数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, asts, labels):\n",
    "        self.texts = texts\n",
    "        self.asts = asts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_encoding = tokenizer(self.texts[idx], return_tensors='pt', padding=True, truncation=True, max_length=266)\n",
    "        ast_encoding = tokenizer(self.asts[idx], return_tensors='pt', padding=True, truncation=True, max_length=266)\n",
    "        label = torch.tensor(int(self.labels[idx]))\n",
    "\n",
    "        return {\n",
    "            'input_ids_text': text_encoding['input_ids'],\n",
    "            'attention_mask_text': text_encoding['attention_mask'],\n",
    "            'input_ids_ast': ast_encoding['input_ids'],\n",
    "            'attention_mask_ast': ast_encoding['attention_mask'],\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "# # 准备数据集\n",
    "# dataset = CustomDataset(data_set['text'], data_set['ast'], data_set['label'])\n",
    "# dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "# 划分训练集和测试集\n",
    "texts_train, texts_test, asts_train, asts_test, labels_train, labels_test = train_test_split(\n",
    "    data_set['text'], data_set['ast'], data_set['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 准备训练集和测试集的数据集\n",
    "train_dataset = CustomDataset(texts_train, asts_train, labels_train)\n",
    "test_dataset = CustomDataset(texts_test, asts_test, labels_test)\n",
    "\n",
    "\n",
    "# 自定义 collate_fn 函数\n",
    "def custom_collate_fn(batch):\n",
    "    input_ids_text = [item['input_ids_text'] for item in batch]\n",
    "    attention_mask_text = [item['attention_mask_text'] for item in batch]\n",
    "    input_ids_ast = [item['input_ids_ast'] for item in batch]\n",
    "    attention_mask_ast = [item['attention_mask_ast'] for item in batch]\n",
    "    labels = torch.tensor([item['label'] for item in batch])\n",
    "\n",
    "    # 使用 pad_sequence 进行填充\n",
    "    input_ids_text = pad_sequence(input_ids_text, batch_first=True)\n",
    "    attention_mask_text = pad_sequence(attention_mask_text, batch_first=True)\n",
    "    input_ids_ast = pad_sequence(input_ids_ast, batch_first=True)\n",
    "    attention_mask_ast = pad_sequence(attention_mask_ast, batch_first=True)\n",
    "\n",
    "    # 将文本序列转换为可变长度序列\n",
    "    lengths_text = torch.sum(attention_mask_text, dim=1)\n",
    "    print('lengths_text shape: ', lengths_text.shape)\n",
    "    packed_text = pack_padded_sequence(input_ids_text, lengths_text, batch_first=True, enforce_sorted=False)\n",
    "    print('packed_text shape', packed_text.shape)\n",
    "\n",
    "    # 将AST序列转换为可变长度序列\n",
    "    lengths_ast = torch.sum(attention_mask_ast, dim=1)\n",
    "    packed_ast = pack_padded_sequence(input_ids_ast, lengths_ast, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "    return {\n",
    "        'packed_text': packed_text,\n",
    "        'attention_mask_text': attention_mask_text,\n",
    "        'packed_ast': packed_ast,\n",
    "        'attention_mask_ast': attention_mask_ast,\n",
    "        'label': labels\n",
    "    }\n",
    "\n",
    "# 创建 DataLoader 时使用 collate_fn 参数\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        inputs_text = batch['input_ids_text'].to(device)\n",
    "        attention_mask_text = batch['attention_mask_text'].to(device)\n",
    "        inputs_ast = batch['input_ids_ast'].to(device)\n",
    "        attention_mask_ast = batch['attention_mask_ast'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=inputs_text, attention_mask=attention_mask_text, inputs_ast=inputs_ast, attention_mask_ast=attention_mask_ast, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 保存模型\n",
    "# model.save_pretrained('your_model_directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs_text = batch['input_ids_text'].to(device)\n",
    "        attention_mask_text = batch['attention_mask_text'].to(device)\n",
    "        inputs_ast = batch['input_ids_ast'].to(device)\n",
    "        attention_mask_ast = batch['attention_mask_ast'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=inputs_text, attention_mask=attention_mask_text,\n",
    "                        inputs_ast=inputs_ast, attention_mask_ast=attention_mask_ast)\n",
    "\n",
    "        predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算测试集准确率\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割线\n",
    "--------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omp parallel for private(i, j) schedule(dynamic, blocksize)', 'omp parallel for private(i, j) schedule(dynamic, blocksize)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(progress,status) omp_throttle(1)', 'omp parallel for schedule(dynamic,4) shared(progress,status) omp_throttle(1)', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(progress,status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status) omp_throttle(1)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', 'omp parallel for schedule(dynamic,4) shared(progress,status)', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(dynamic,4) shared(status)', 'omp parallel for schedule(static,1) shared(progress, status) omp_throttle(1)', 'omp parallel for schedule(static,8) shared(progress,status) omp_throttle(1)', 'omp parallel for schedule(static,1) shared(progress,status) omp_throttle(1)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for schedule(dynamic,4) shared(status)', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', 'omp parallel for private (i)', 'omp parallel for private (i)', 'omp parallel for private (j)', 'omp parallel for private (j2, i)', '0', '0', 'omp parallel for private (i)', 'omp parallel for private (j)', 'omp parallel for private (j2, i)', '0', '0', 'omp parallel for private (j, k)', 'omp parallel for private (j, k)', '0', '0', '0', '0', '0', 'omp parallel for private(k)', 'omp parallel for private(j,k)', 'omp parallel for', '0', '0', '0', '0', '0', 'omp parallel for', 'omp parallel for private (j)', '0', '0', '0', 'omp parallel for', 'omp parallel for private (j)', '0', '0', '0', '0', 'omp parallel for private (j,k)', '0', '0', 'omp parallel for private (q, p, s)', '0', '0', '0', 'omp parallel for private (j, k)', '0', '0', '0', '0', 'omp parallel for private (j)', 'omp parallel for private (j)', 'omp parallel for', 'omp parallel for private (j)', '0', '0', 'omp parallel for private (j)', '0', '0', 'omp parallel for', 'omp parallel for', '0', '0', 'omp parallel for private(j,acc,k)', '0', '0', '0', 'omp parallel for private (j) schedule(static)', 'omp parallel for private (j, k) schedule(static)', '0', '0', '0', 'omp parallel for private(j)', 'omp parallel for private(j,k)', '0', '0', '0', 'omp parallel for schedule(static)', '0', '0', 'omp parallel for private (j, k)', '0', '0', 'omp parallel for private (i)', 'omp parallel for', '0', '0', 'omp parallel for private (j)', 'omp parallel for private (j, k)', '0', 'omp parallel for private (i, j)', '0', '0', '0', '0', '0', 'omp parallel for private (j, i)', '0', '0', 'omp parallel for private (j, w)', 'omp parallel for private (j, w)', '0', '0', '0', 'omp parallel for private (i, cnt) collapse(2) schedule(static)', 'omp parallel for private (i, cnt) collapse(2) schedule(static)', 'omp parallel for', 'omp parallel for private (i) collapse(2) schedule(static)', '0', '0', 'omp parallel for', 'omp parallel for', 'omp parallel for', 'omp parallel for', 'omp parallel for', 'omp parallel for', '0', '0', 'omp parallel for private(j) collapse(2) schedule(static)', '0', '0', 'omp parallel for private (j,k) collapse(2)', '0', '0', 'omp parallel for', 'omp parallel for private(i,j) collapse(2) schedule(static)', 'omp parallel for private(i,j) collapse(2) schedule(static)', 'omp parallel for private(i,j) collapse(2) schedule(static)', '0', '0', '0', 'omp parallel for private (iy, ix)', '0', '0', '0', '0', '0', 'omp parallel for schedule(static)', 'omp parallel for schedule(static)', '0', '0', 'omp parallel for schedule(static)', 'omp parallel for schedule(static)', '0', '0', 'omp parallel for private(i,j,t) schedule(static) collapse (2)', '0', '0', 'omp parallel for']\n",
      "['2', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2', '2', '2', '2', '0', '0', '2', '2', '2', '0', '0', '2', '2', '0', '0', '0', '0', '0', '2', '2', '1', '0', '0', '0', '0', '0', '1', '2', '0', '0', '0', '1', '2', '0', '0', '0', '0', '2', '0', '0', '2', '0', '0', '0', '2', '0', '0', '0', '0', '2', '2', '1', '2', '0', '0', '2', '0', '0', '1', '1', '0', '0', '2', '0', '0', '0', '2', '2', '0', '0', '0', '2', '2', '0', '0', '0', '1', '0', '0', '2', '0', '0', '2', '1', '0', '0', '2', '2', '0', '2', '0', '0', '0', '0', '0', '2', '0', '0', '2', '2', '0', '0', '0', '2', '2', '1', '2', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '2', '0', '0', '2', '0', '0', '1', '2', '2', '2', '0', '0', '0', '2', '0', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '2', '0', '0', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  <__main__.MyDataset object at 0x17f879f30>\n",
      "val_dataset:  <__main__.MyDataset object at 0x1691b3d90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solochan/anaconda3/envs/Pragformer/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, texts, asts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.asts = asts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        ast = str(self.asts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        inputs = self.tokenizer(text, ast, return_tensors='pt', max_length=self.max_len, truncation=True, padding='max_length')\n",
    "        inputs['labels'] = torch.tensor(label)\n",
    "        # print('mydata: ', inputs)\n",
    "        return inputs\n",
    "\n",
    "# Encode labels 这种编码不适合当前的任务\n",
    "# label_encoder = LabelEncoder()\n",
    "# data_set['label'] = label_encoder.fit_transform(data_set['label'])\n",
    "# print('\\n', data_set['label'])\n",
    "\n",
    "def label_encoder(labels:list):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        if 'omp parallel for' in label and 'private' not in label and 'reduction' not in label:\n",
    "            new_labels.append('1')\n",
    "        elif 'omp parallel for' in label and 'private' in label and 'reduction' not in label:\n",
    "            new_labels.append('2')\n",
    "        elif 'omp parallel for' in label and 'reduction' in label and 'private' not in label:\n",
    "            new_labels.append('3')\n",
    "        elif 'omp parallel for' in label and 'reduction' in label and 'private' in label:\n",
    "            new_labels.append(\"4\")\n",
    "        else:\n",
    "            new_labels.append(\"0\")\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     return {\n",
    "#         'input_ids': pad_sequence([item['input_ids'] for item in batch], batch_first=True),\n",
    "#         'attention_mask': pad_sequence([item['attention_mask'] for item in batch], batch_first=True),\n",
    "#         'labels': torch.tensor([item['labels'] for item in batch])\n",
    "#     }\n",
    "#\n",
    "print(data_set['label'])\n",
    "data_set['label'] = label_encoder(data_set['label'])\n",
    "print(data_set['label'])\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, val_texts, train_asts, val_asts, train_labels, val_labels = train_test_split(\n",
    "    data_set['text'], data_set['ast'], data_set['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "# Define datasets and dataloaders\n",
    "train_dataset = MyDataset(train_texts, train_asts, train_labels, tokenizer, max_len=512)\n",
    "val_dataset = MyDataset(val_texts, val_asts, val_labels, tokenizer, max_len=512)\n",
    "\n",
    "print('train_dataset: ', train_dataset)\n",
    "print('val_dataset: ', val_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define training parameters\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataloader)\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_dataloader):\n",
    "    print(\"input_ids: \", input_ids)\n",
    "    print(\"attention_mask: \", attention_mask)\n",
    "    print(\"token_type_ids: \", token_type_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "        print(\"inputs: \\n\", inputs)\n",
    "        # print('training inputs: ', inputs)\n",
    "    #     optimizer.zero_grad()\n",
    "    #     outputs = model(**inputs)\n",
    "    #     loss = outputs.loss\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "\n",
    "    # # Validation\n",
    "    # model.eval()\n",
    "    # val_preds = []\n",
    "    # val_true = []\n",
    "    # with torch.no_grad():\n",
    "    #     for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch + 1} - Validation\"):\n",
    "    #         inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "            \n",
    "    #         outputs= model(**inputs)\n",
    "    #         logits = outputs.logits\n",
    "    #         preds = torch.argmax(logits, dim=1)\n",
    "    #         val_preds.extend(preds.cpu().numpy())\n",
    "    #         val_true.extend(inputs['label'].cpu().numpy())\n",
    "\n",
    "    # # Calculate validation accuracy and print metrics\n",
    "    # accuracy = accuracy_score(val_true, val_preds)\n",
    "    # report = classification_report(val_true, val_preds, target_names=label_encoder.classes_)\n",
    "    # print(f\"Epoch {epoch + 1} - Validation Accuracy: {accuracy:.4f}\")\n",
    "    # print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pragformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
